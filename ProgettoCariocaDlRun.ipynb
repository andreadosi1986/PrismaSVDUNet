{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOG7+37BdhUnNfhLbFtoYGc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreadosi1986/PrismaSVDUNet/blob/master/ProgettoCariocaDlRun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOuSt7EWGRWl",
        "outputId": "e5851178-b2cf-41ca-88f1-d7e6fec7353c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDrfZKr7SrJp",
        "outputId": "415423b1-0714-47a0-d93a-09f08c7b5342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation_models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.18.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.5.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.11.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.15.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr6tmKDya4hu",
        "outputId": "ec7e454b-d055-4ed3-9c61-99c2ec737e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 26 08:13:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "import skimage\n",
        "from skimage.measure import regionprops\n",
        "import random\n",
        "import pandas as pd\n",
        "from skimage import filters\n",
        "import tifffile as tiff\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import pickle"
      ],
      "metadata": {
        "id": "pRK-n7K9Gx0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### IMPORT TRAINING TEST SET AND CORRISPONDING LABELLING ####"
      ],
      "metadata": {
        "id": "Cqru6rVFG42Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.load('/content/drive/MyDrive/datamining/prisma/Sardinia/X_train4classesNoNoise.npy')"
      ],
      "metadata": {
        "id": "95eCMIBxG46Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.load('/content/drive/MyDrive/datamining/prisma/Sardinia/X_test4classesNoNoise.npy')\n",
        "y_train_cat = np.load('/content/drive/MyDrive/datamining/prisma/Sardinia/y_train_cat4classesNoNoise.npy')\n",
        "y_test_cat = np.load('/content/drive/MyDrive/datamining/prisma/Sardinia/y_test_cat4classesNoNoise.npy')"
      ],
      "metadata": {
        "id": "vBuVFe7dG49Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.load('/content/drive/MyDrive/datamining/prisma/Sardinia/y_train4classesNoNoise.npy')\n",
        "y_test = np.load('/content/drive/MyDrive/datamining/prisma/Sardinia/y_test4classesNoNoise.npy')"
      ],
      "metadata": {
        "id": "tbVffVSmQaE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_test.shape, y_train_cat.shape, y_test_cat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQWwuV0sfFlz",
        "outputId": "c8f23c58-7880-45d4-fcb3-c35dfdab7335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2673, 128, 128, 1) (669, 128, 128, 1) (2673, 128, 128, 4) (669, 128, 128, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#class_weight_array = np.load('/content/drive/MyDrive/datamining/prisma/Sardinia/class_weight.npy')"
      ],
      "metadata": {
        "id": "ELPQ_Rit4vdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(class_weight_array)"
      ],
      "metadata": {
        "id": "bJLoUTC87Gor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classes = np.array([0,1,2,3,4,5])"
      ],
      "metadata": {
        "id": "ZE_yL0blHFAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class_weight = {0:class_weight_array[0], 1:class_weight_array[1], 2:class_weight_array[2], 3:class_weight_array[3], 4:class_weight_array[4], 5:class_weight_array[5]}"
      ],
      "metadata": {
        "id": "lmPl5HHB5D7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.python.keras.engine.training_utils_v1 import standardize_weights\n",
        "#standardize_weights(classes, class_weight=class_weight)"
      ],
      "metadata": {
        "id": "OkP3bwz7Bha0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models as sm\n",
        "#class_weights = [0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666]\n",
        "#dice_loss = sm.losses.DiceLoss(class_weights=class_weight_array) \n",
        "focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "#total_loss = dice_loss + (1 * focal_loss)\n",
        "#jaccard_loss = sm.losses.bce_jaccard_loss(class_weights=class_weight_array)"
      ],
      "metadata": {
        "id": "j-ns_v7xSlRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################ U-NET BUILD ###########################################\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "\n",
        "def multi_unet_model(n_classes, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
        "#Build the model\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
        "    s = inputs\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    \n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "     \n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "     \n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "     \n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "    \n",
        "    #Expansive path \n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "     \n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "     \n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "     \n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "     \n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
        "     \n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
        "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    #model.summary()\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "0TfbeH4LG4_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = X_train.shape[1]\n",
        "IMG_WIDTH  = X_train.shape[2]\n",
        "IMG_CHANNELS = X_train.shape[3]\n",
        "n_classes=4"
      ],
      "metadata": {
        "id": "1j_z_QSlG5EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#total_loss= weightedLoss(keras.losses.categorical_crossentropy, class_weights)\n",
        "#model = multi_unet_model(n_classes, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "#model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "vIPPShaHJ5t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#total_loss= weightedLoss(keras.losses.categorical_crossentropy, class_weights)\n",
        "model = multi_unet_model(n_classes, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "model.compile(optimizer='adam', loss= focal_loss, metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTVteiUlTorW",
        "outputId": "2148a222-cdc5-4f03-9df7-1699a3273e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 128, 128, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_209 (Conv2D)            (None, 128, 128, 16  160         ['input_12[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_99 (Dropout)           (None, 128, 128, 16  0           ['conv2d_209[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_210 (Conv2D)            (None, 128, 128, 16  2320        ['dropout_99[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_44 (MaxPooling2D  (None, 64, 64, 16)  0           ['conv2d_210[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_211 (Conv2D)            (None, 64, 64, 32)   4640        ['max_pooling2d_44[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_100 (Dropout)          (None, 64, 64, 32)   0           ['conv2d_211[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_212 (Conv2D)            (None, 64, 64, 32)   9248        ['dropout_100[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_45 (MaxPooling2D  (None, 32, 32, 32)  0           ['conv2d_212[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_213 (Conv2D)            (None, 32, 32, 64)   18496       ['max_pooling2d_45[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_101 (Dropout)          (None, 32, 32, 64)   0           ['conv2d_213[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_214 (Conv2D)            (None, 32, 32, 64)   36928       ['dropout_101[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_46 (MaxPooling2D  (None, 16, 16, 64)  0           ['conv2d_214[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_215 (Conv2D)            (None, 16, 16, 128)  73856       ['max_pooling2d_46[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_102 (Dropout)          (None, 16, 16, 128)  0           ['conv2d_215[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_216 (Conv2D)            (None, 16, 16, 128)  147584      ['dropout_102[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_47 (MaxPooling2D  (None, 8, 8, 128)   0           ['conv2d_216[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_217 (Conv2D)            (None, 8, 8, 256)    295168      ['max_pooling2d_47[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_103 (Dropout)          (None, 8, 8, 256)    0           ['conv2d_217[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_218 (Conv2D)            (None, 8, 8, 256)    590080      ['dropout_103[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_44 (Conv2DTra  (None, 16, 16, 128)  131200     ['conv2d_218[0][0]']             \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_44 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_transpose_44[0][0]',    \n",
            "                                                                  'conv2d_216[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_219 (Conv2D)            (None, 16, 16, 128)  295040      ['concatenate_44[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_104 (Dropout)          (None, 16, 16, 128)  0           ['conv2d_219[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_220 (Conv2D)            (None, 16, 16, 128)  147584      ['dropout_104[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_45 (Conv2DTra  (None, 32, 32, 64)  32832       ['conv2d_220[0][0]']             \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_45 (Concatenate)   (None, 32, 32, 128)  0           ['conv2d_transpose_45[0][0]',    \n",
            "                                                                  'conv2d_214[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_221 (Conv2D)            (None, 32, 32, 64)   73792       ['concatenate_45[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_105 (Dropout)          (None, 32, 32, 64)   0           ['conv2d_221[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_222 (Conv2D)            (None, 32, 32, 64)   36928       ['dropout_105[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_46 (Conv2DTra  (None, 64, 64, 32)  8224        ['conv2d_222[0][0]']             \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_46 (Concatenate)   (None, 64, 64, 64)   0           ['conv2d_transpose_46[0][0]',    \n",
            "                                                                  'conv2d_212[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_223 (Conv2D)            (None, 64, 64, 32)   18464       ['concatenate_46[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_106 (Dropout)          (None, 64, 64, 32)   0           ['conv2d_223[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_224 (Conv2D)            (None, 64, 64, 32)   9248        ['dropout_106[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_47 (Conv2DTra  (None, 128, 128, 16  2064       ['conv2d_224[0][0]']             \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_47 (Concatenate)   (None, 128, 128, 32  0           ['conv2d_transpose_47[0][0]',    \n",
            "                                )                                 'conv2d_210[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_225 (Conv2D)            (None, 128, 128, 16  4624        ['concatenate_47[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_107 (Dropout)          (None, 128, 128, 16  0           ['conv2d_225[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_226 (Conv2D)            (None, 128, 128, 16  2320        ['dropout_107[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_227 (Conv2D)            (None, 128, 128, 4)  68          ['conv2d_226[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,940,868\n",
            "Trainable params: 1,940,868\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "history = model.fit(X_train, y_train_cat, \n",
        "                    batch_size = 16, \n",
        "                    verbose=1, \n",
        "                    epochs=300, \n",
        "                    validation_data=(X_test, y_test_cat), \n",
        "                    #sample_weight=class_weight_array,\n",
        "                    shuffle=False)\n",
        "\n",
        "print(\"Total model fit time: \", time.time() - start, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1ajrWx5KLrM",
        "outputId": "e3b9e416-5af4-4c1a-80c6-678b9297973e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "168/168 [==============================] - 10s 47ms/step - loss: 0.0175 - accuracy: 0.7777 - val_loss: 0.0138 - val_accuracy: 0.8756\n",
            "Epoch 2/300\n",
            "168/168 [==============================] - 7s 45ms/step - loss: 0.0091 - accuracy: 0.8752 - val_loss: 0.0107 - val_accuracy: 0.8833\n",
            "Epoch 3/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0076 - accuracy: 0.8768 - val_loss: 0.0113 - val_accuracy: 0.8824\n",
            "Epoch 4/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0067 - accuracy: 0.8796 - val_loss: 0.0067 - val_accuracy: 0.8881\n",
            "Epoch 5/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0051 - accuracy: 0.8979 - val_loss: 0.0049 - val_accuracy: 0.9146\n",
            "Epoch 6/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0042 - accuracy: 0.9161 - val_loss: 0.0069 - val_accuracy: 0.9106\n",
            "Epoch 7/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0033 - accuracy: 0.9319 - val_loss: 0.0079 - val_accuracy: 0.9129\n",
            "Epoch 8/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0029 - accuracy: 0.9388 - val_loss: 0.0049 - val_accuracy: 0.9260\n",
            "Epoch 9/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0024 - accuracy: 0.9467 - val_loss: 0.0055 - val_accuracy: 0.9258\n",
            "Epoch 10/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0022 - accuracy: 0.9515 - val_loss: 0.0033 - val_accuracy: 0.9328\n",
            "Epoch 11/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0020 - accuracy: 0.9549 - val_loss: 0.0033 - val_accuracy: 0.9433\n",
            "Epoch 12/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0018 - accuracy: 0.9580 - val_loss: 0.0039 - val_accuracy: 0.9427\n",
            "Epoch 13/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0016 - accuracy: 0.9613 - val_loss: 0.0036 - val_accuracy: 0.9457\n",
            "Epoch 14/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0015 - accuracy: 0.9636 - val_loss: 0.0035 - val_accuracy: 0.9484\n",
            "Epoch 15/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0015 - accuracy: 0.9649 - val_loss: 0.0034 - val_accuracy: 0.9502\n",
            "Epoch 16/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0014 - accuracy: 0.9671 - val_loss: 0.0029 - val_accuracy: 0.9552\n",
            "Epoch 17/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0013 - accuracy: 0.9676 - val_loss: 0.0030 - val_accuracy: 0.9550\n",
            "Epoch 18/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0012 - accuracy: 0.9694 - val_loss: 0.0062 - val_accuracy: 0.9340\n",
            "Epoch 19/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0013 - accuracy: 0.9681 - val_loss: 0.0025 - val_accuracy: 0.9596\n",
            "Epoch 20/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0012 - accuracy: 0.9708 - val_loss: 0.0031 - val_accuracy: 0.9552\n",
            "Epoch 21/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0012 - accuracy: 0.9714 - val_loss: 0.0021 - val_accuracy: 0.9639\n",
            "Epoch 22/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0013 - accuracy: 0.9692 - val_loss: 0.0025 - val_accuracy: 0.9594\n",
            "Epoch 23/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0013 - accuracy: 0.9699 - val_loss: 0.0018 - val_accuracy: 0.9678\n",
            "Epoch 24/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0011 - accuracy: 0.9729 - val_loss: 0.0020 - val_accuracy: 0.9673\n",
            "Epoch 25/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0010 - accuracy: 0.9744 - val_loss: 0.0015 - val_accuracy: 0.9715\n",
            "Epoch 26/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 9.6646e-04 - accuracy: 0.9754 - val_loss: 0.0015 - val_accuracy: 0.9723\n",
            "Epoch 27/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 9.6441e-04 - accuracy: 0.9757 - val_loss: 0.0017 - val_accuracy: 0.9704\n",
            "Epoch 28/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 9.5688e-04 - accuracy: 0.9759 - val_loss: 0.0019 - val_accuracy: 0.9688\n",
            "Epoch 29/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 9.1004e-04 - accuracy: 0.9768 - val_loss: 0.0018 - val_accuracy: 0.9714\n",
            "Epoch 30/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.9334e-04 - accuracy: 0.9772 - val_loss: 0.0020 - val_accuracy: 0.9700\n",
            "Epoch 31/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.6984e-04 - accuracy: 0.9778 - val_loss: 0.0020 - val_accuracy: 0.9687\n",
            "Epoch 32/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 9.4169e-04 - accuracy: 0.9765 - val_loss: 0.0015 - val_accuracy: 0.9719\n",
            "Epoch 33/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0010 - accuracy: 0.9752 - val_loss: 0.0015 - val_accuracy: 0.9740\n",
            "Epoch 34/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.8931e-04 - accuracy: 0.9775 - val_loss: 0.0014 - val_accuracy: 0.9748\n",
            "Epoch 35/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.8697e-04 - accuracy: 0.9776 - val_loss: 0.0014 - val_accuracy: 0.9752\n",
            "Epoch 36/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.2116e-04 - accuracy: 0.9789 - val_loss: 0.0017 - val_accuracy: 0.9725\n",
            "Epoch 37/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.0684e-04 - accuracy: 0.9793 - val_loss: 0.0016 - val_accuracy: 0.9744\n",
            "Epoch 38/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0013 - accuracy: 0.9719 - val_loss: 0.0016 - val_accuracy: 0.9681\n",
            "Epoch 39/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0012 - accuracy: 0.9719 - val_loss: 0.0015 - val_accuracy: 0.9721\n",
            "Epoch 40/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 9.1864e-04 - accuracy: 0.9771 - val_loss: 0.0014 - val_accuracy: 0.9753\n",
            "Epoch 41/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.3783e-04 - accuracy: 0.9787 - val_loss: 0.0013 - val_accuracy: 0.9760\n",
            "Epoch 42/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.8532e-04 - accuracy: 0.9798 - val_loss: 0.0013 - val_accuracy: 0.9777\n",
            "Epoch 43/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.5119e-04 - accuracy: 0.9806 - val_loss: 0.0014 - val_accuracy: 0.9770\n",
            "Epoch 44/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.3755e-04 - accuracy: 0.9809 - val_loss: 0.0014 - val_accuracy: 0.9774\n",
            "Epoch 45/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.2290e-04 - accuracy: 0.9812 - val_loss: 0.0013 - val_accuracy: 0.9784\n",
            "Epoch 46/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.2516e-04 - accuracy: 0.9812 - val_loss: 0.0013 - val_accuracy: 0.9781\n",
            "Epoch 47/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.0075e-04 - accuracy: 0.9818 - val_loss: 0.0015 - val_accuracy: 0.9777\n",
            "Epoch 48/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.9976e-04 - accuracy: 0.9818 - val_loss: 0.0014 - val_accuracy: 0.9782\n",
            "Epoch 49/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.1982e-04 - accuracy: 0.9816 - val_loss: 0.0015 - val_accuracy: 0.9777\n",
            "Epoch 50/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.0695e-04 - accuracy: 0.9818 - val_loss: 0.0013 - val_accuracy: 0.9789\n",
            "Epoch 51/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.0781e-04 - accuracy: 0.9818 - val_loss: 0.0014 - val_accuracy: 0.9776\n",
            "Epoch 52/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0012 - accuracy: 0.9722 - val_loss: 0.0013 - val_accuracy: 0.9747\n",
            "Epoch 53/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 9.0314e-04 - accuracy: 0.9779 - val_loss: 0.0013 - val_accuracy: 0.9770\n",
            "Epoch 54/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.7039e-04 - accuracy: 0.9806 - val_loss: 0.0014 - val_accuracy: 0.9764\n",
            "Epoch 55/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.3036e-04 - accuracy: 0.9813 - val_loss: 0.0014 - val_accuracy: 0.9781\n",
            "Epoch 56/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.9822e-04 - accuracy: 0.9820 - val_loss: 0.0014 - val_accuracy: 0.9775\n",
            "Epoch 57/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.7696e-04 - accuracy: 0.9826 - val_loss: 0.0012 - val_accuracy: 0.9798\n",
            "Epoch 58/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.7107e-04 - accuracy: 0.9827 - val_loss: 0.0013 - val_accuracy: 0.9799\n",
            "Epoch 59/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.5051e-04 - accuracy: 0.9832 - val_loss: 0.0013 - val_accuracy: 0.9793\n",
            "Epoch 60/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.4353e-04 - accuracy: 0.9833 - val_loss: 0.0014 - val_accuracy: 0.9797\n",
            "Epoch 61/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.3178e-04 - accuracy: 0.9836 - val_loss: 0.0014 - val_accuracy: 0.9798\n",
            "Epoch 62/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.2979e-04 - accuracy: 0.9837 - val_loss: 0.0013 - val_accuracy: 0.9804\n",
            "Epoch 63/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.2679e-04 - accuracy: 0.9838 - val_loss: 0.0013 - val_accuracy: 0.9807\n",
            "Epoch 64/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.3670e-04 - accuracy: 0.9836 - val_loss: 0.0013 - val_accuracy: 0.9804\n",
            "Epoch 65/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.2820e-04 - accuracy: 0.9838 - val_loss: 0.0012 - val_accuracy: 0.9805\n",
            "Epoch 66/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.1025e-04 - accuracy: 0.9841 - val_loss: 0.0013 - val_accuracy: 0.9813\n",
            "Epoch 67/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.6276e-04 - accuracy: 0.9831 - val_loss: 0.0013 - val_accuracy: 0.9805\n",
            "Epoch 68/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0011 - accuracy: 0.9761 - val_loss: 0.0014 - val_accuracy: 0.9741\n",
            "Epoch 69/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.3037e-04 - accuracy: 0.9797 - val_loss: 0.0013 - val_accuracy: 0.9784\n",
            "Epoch 70/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.0641e-04 - accuracy: 0.9822 - val_loss: 0.0013 - val_accuracy: 0.9791\n",
            "Epoch 71/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.5097e-04 - accuracy: 0.9834 - val_loss: 0.0012 - val_accuracy: 0.9807\n",
            "Epoch 72/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.2504e-04 - accuracy: 0.9839 - val_loss: 0.0012 - val_accuracy: 0.9811\n",
            "Epoch 73/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.1163e-04 - accuracy: 0.9843 - val_loss: 0.0013 - val_accuracy: 0.9803\n",
            "Epoch 74/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.0258e-04 - accuracy: 0.9844 - val_loss: 0.0013 - val_accuracy: 0.9813\n",
            "Epoch 75/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.8843e-04 - accuracy: 0.9848 - val_loss: 0.0013 - val_accuracy: 0.9807\n",
            "Epoch 76/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.9567e-04 - accuracy: 0.9847 - val_loss: 0.0012 - val_accuracy: 0.9816\n",
            "Epoch 77/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.8750e-04 - accuracy: 0.9849 - val_loss: 0.0013 - val_accuracy: 0.9811\n",
            "Epoch 78/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.7528e-04 - accuracy: 0.9851 - val_loss: 0.0013 - val_accuracy: 0.9819\n",
            "Epoch 79/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.7165e-04 - accuracy: 0.9853 - val_loss: 0.0015 - val_accuracy: 0.9802\n",
            "Epoch 80/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.7561e-04 - accuracy: 0.9852 - val_loss: 0.0013 - val_accuracy: 0.9821\n",
            "Epoch 81/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.6890e-04 - accuracy: 0.9853 - val_loss: 0.0012 - val_accuracy: 0.9821\n",
            "Epoch 82/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.6391e-04 - accuracy: 0.9855 - val_loss: 0.0012 - val_accuracy: 0.9822\n",
            "Epoch 83/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.6614e-04 - accuracy: 0.9854 - val_loss: 0.0015 - val_accuracy: 0.9798\n",
            "Epoch 84/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.5929e-04 - accuracy: 0.9856 - val_loss: 0.0014 - val_accuracy: 0.9817\n",
            "Epoch 85/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.7890e-04 - accuracy: 0.9852 - val_loss: 0.0014 - val_accuracy: 0.9812\n",
            "Epoch 86/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.7469e-04 - accuracy: 0.9853 - val_loss: 0.0013 - val_accuracy: 0.9820\n",
            "Epoch 87/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.5902e-04 - accuracy: 0.9856 - val_loss: 0.0012 - val_accuracy: 0.9830\n",
            "Epoch 88/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.5755e-04 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 0.9821\n",
            "Epoch 89/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0024 - accuracy: 0.9543 - val_loss: 0.0019 - val_accuracy: 0.9629\n",
            "Epoch 90/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0012 - accuracy: 0.9716 - val_loss: 0.0015 - val_accuracy: 0.9738\n",
            "Epoch 91/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.5897e-04 - accuracy: 0.9790 - val_loss: 0.0013 - val_accuracy: 0.9779\n",
            "Epoch 92/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.3970e-04 - accuracy: 0.9814 - val_loss: 0.0013 - val_accuracy: 0.9789\n",
            "Epoch 93/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.8193e-04 - accuracy: 0.9827 - val_loss: 0.0012 - val_accuracy: 0.9802\n",
            "Epoch 94/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.4307e-04 - accuracy: 0.9836 - val_loss: 0.0014 - val_accuracy: 0.9801\n",
            "Epoch 95/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.2952e-04 - accuracy: 0.9840 - val_loss: 0.0012 - val_accuracy: 0.9813\n",
            "Epoch 96/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.0004e-04 - accuracy: 0.9846 - val_loss: 0.0013 - val_accuracy: 0.9816\n",
            "Epoch 97/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.8273e-04 - accuracy: 0.9850 - val_loss: 0.0013 - val_accuracy: 0.9820\n",
            "Epoch 98/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.6820e-04 - accuracy: 0.9853 - val_loss: 0.0014 - val_accuracy: 0.9814\n",
            "Epoch 99/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.6121e-04 - accuracy: 0.9855 - val_loss: 0.0013 - val_accuracy: 0.9822\n",
            "Epoch 100/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.5350e-04 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 0.9824\n",
            "Epoch 101/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.4609e-04 - accuracy: 0.9859 - val_loss: 0.0013 - val_accuracy: 0.9824\n",
            "Epoch 102/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.4027e-04 - accuracy: 0.9860 - val_loss: 0.0014 - val_accuracy: 0.9819\n",
            "Epoch 103/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.3423e-04 - accuracy: 0.9862 - val_loss: 0.0012 - val_accuracy: 0.9830\n",
            "Epoch 104/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.4102e-04 - accuracy: 0.9861 - val_loss: 0.0012 - val_accuracy: 0.9829\n",
            "Epoch 105/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.3516e-04 - accuracy: 0.9863 - val_loss: 0.0012 - val_accuracy: 0.9826\n",
            "Epoch 106/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.2792e-04 - accuracy: 0.9864 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 107/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.2102e-04 - accuracy: 0.9866 - val_loss: 0.0013 - val_accuracy: 0.9831\n",
            "Epoch 108/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.2127e-04 - accuracy: 0.9866 - val_loss: 0.0011 - val_accuracy: 0.9837\n",
            "Epoch 109/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.1534e-04 - accuracy: 0.9867 - val_loss: 0.0013 - val_accuracy: 0.9832\n",
            "Epoch 110/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.7741e-04 - accuracy: 0.9836 - val_loss: 0.0014 - val_accuracy: 0.9817\n",
            "Epoch 111/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.0007e-04 - accuracy: 0.9849 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 112/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.4084e-04 - accuracy: 0.9861 - val_loss: 0.0012 - val_accuracy: 0.9834\n",
            "Epoch 113/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.2653e-04 - accuracy: 0.9865 - val_loss: 0.0013 - val_accuracy: 0.9834\n",
            "Epoch 114/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.1781e-04 - accuracy: 0.9850 - val_loss: 0.0014 - val_accuracy: 0.9761\n",
            "Epoch 115/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 7.3786e-04 - accuracy: 0.9823 - val_loss: 0.0012 - val_accuracy: 0.9823\n",
            "Epoch 116/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.7498e-04 - accuracy: 0.9854 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 117/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.5187e-04 - accuracy: 0.9860 - val_loss: 0.0012 - val_accuracy: 0.9834\n",
            "Epoch 118/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.2148e-04 - accuracy: 0.9866 - val_loss: 0.0012 - val_accuracy: 0.9835\n",
            "Epoch 119/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.1482e-04 - accuracy: 0.9868 - val_loss: 0.0013 - val_accuracy: 0.9830\n",
            "Epoch 120/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.1781e-04 - accuracy: 0.9867 - val_loss: 0.0014 - val_accuracy: 0.9830\n",
            "Epoch 121/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.0887e-04 - accuracy: 0.9869 - val_loss: 0.0013 - val_accuracy: 0.9839\n",
            "Epoch 122/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.9087e-04 - accuracy: 0.9873 - val_loss: 0.0013 - val_accuracy: 0.9839\n",
            "Epoch 123/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.0174e-04 - accuracy: 0.9871 - val_loss: 0.0011 - val_accuracy: 0.9845\n",
            "Epoch 124/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8697e-04 - accuracy: 0.9875 - val_loss: 0.0013 - val_accuracy: 0.9842\n",
            "Epoch 125/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8363e-04 - accuracy: 0.9875 - val_loss: 0.0012 - val_accuracy: 0.9846\n",
            "Epoch 126/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.9100e-04 - accuracy: 0.9874 - val_loss: 0.0013 - val_accuracy: 0.9836\n",
            "Epoch 127/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8710e-04 - accuracy: 0.9875 - val_loss: 0.0012 - val_accuracy: 0.9839\n",
            "Epoch 128/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8832e-04 - accuracy: 0.9874 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 129/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8508e-04 - accuracy: 0.9875 - val_loss: 0.0012 - val_accuracy: 0.9848\n",
            "Epoch 130/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.7588e-04 - accuracy: 0.9877 - val_loss: 0.0013 - val_accuracy: 0.9843\n",
            "Epoch 131/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.9221e-04 - accuracy: 0.9874 - val_loss: 0.0012 - val_accuracy: 0.9848\n",
            "Epoch 132/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.0267e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9846\n",
            "Epoch 133/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8699e-04 - accuracy: 0.9875 - val_loss: 0.0013 - val_accuracy: 0.9835\n",
            "Epoch 134/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.5253e-04 - accuracy: 0.9863 - val_loss: 0.0013 - val_accuracy: 0.9794\n",
            "Epoch 135/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0011 - accuracy: 0.9768 - val_loss: 0.0012 - val_accuracy: 0.9803\n",
            "Epoch 136/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.4248e-04 - accuracy: 0.9843 - val_loss: 0.0011 - val_accuracy: 0.9832\n",
            "Epoch 137/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.5273e-04 - accuracy: 0.9861 - val_loss: 0.0011 - val_accuracy: 0.9840\n",
            "Epoch 138/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.1770e-04 - accuracy: 0.9868 - val_loss: 0.0012 - val_accuracy: 0.9842\n",
            "Epoch 139/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 5.0176e-04 - accuracy: 0.9872 - val_loss: 0.0013 - val_accuracy: 0.9840\n",
            "Epoch 140/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.9133e-04 - accuracy: 0.9874 - val_loss: 0.0012 - val_accuracy: 0.9845\n",
            "Epoch 141/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8100e-04 - accuracy: 0.9876 - val_loss: 0.0012 - val_accuracy: 0.9848\n",
            "Epoch 142/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.7550e-04 - accuracy: 0.9878 - val_loss: 0.0012 - val_accuracy: 0.9852\n",
            "Epoch 143/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.7260e-04 - accuracy: 0.9879 - val_loss: 0.0013 - val_accuracy: 0.9850\n",
            "Epoch 144/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.6502e-04 - accuracy: 0.9880 - val_loss: 0.0013 - val_accuracy: 0.9849\n",
            "Epoch 145/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.6163e-04 - accuracy: 0.9881 - val_loss: 0.0012 - val_accuracy: 0.9853\n",
            "Epoch 146/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.6210e-04 - accuracy: 0.9881 - val_loss: 0.0012 - val_accuracy: 0.9844\n",
            "Epoch 147/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8657e-04 - accuracy: 0.9877 - val_loss: 0.0011 - val_accuracy: 0.9849\n",
            "Epoch 148/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.6232e-04 - accuracy: 0.9881 - val_loss: 0.0012 - val_accuracy: 0.9849\n",
            "Epoch 149/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.5788e-04 - accuracy: 0.9882 - val_loss: 0.0012 - val_accuracy: 0.9856\n",
            "Epoch 150/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.5513e-04 - accuracy: 0.9883 - val_loss: 0.0012 - val_accuracy: 0.9855\n",
            "Epoch 151/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.5498e-04 - accuracy: 0.9883 - val_loss: 0.0012 - val_accuracy: 0.9853\n",
            "Epoch 152/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.5278e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9854\n",
            "Epoch 153/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.4787e-04 - accuracy: 0.9885 - val_loss: 0.0013 - val_accuracy: 0.9851\n",
            "Epoch 154/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.5847e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9855\n",
            "Epoch 155/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.4640e-04 - accuracy: 0.9885 - val_loss: 0.0012 - val_accuracy: 0.9850\n",
            "Epoch 156/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.7347e-04 - accuracy: 0.9879 - val_loss: 0.0013 - val_accuracy: 0.9844\n",
            "Epoch 157/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.6696e-04 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 0.9847\n",
            "Epoch 158/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.9473e-04 - accuracy: 0.9876 - val_loss: 0.0013 - val_accuracy: 0.9830\n",
            "Epoch 159/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8094e-04 - accuracy: 0.9878 - val_loss: 0.0012 - val_accuracy: 0.9847\n",
            "Epoch 160/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.6366e-04 - accuracy: 0.9882 - val_loss: 0.0012 - val_accuracy: 0.9850\n",
            "Epoch 161/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8082e-04 - accuracy: 0.9879 - val_loss: 0.0014 - val_accuracy: 0.9812\n",
            "Epoch 162/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.3814e-04 - accuracy: 0.9867 - val_loss: 0.0013 - val_accuracy: 0.9828\n",
            "Epoch 163/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 5.9719e-04 - accuracy: 0.9855 - val_loss: 0.0012 - val_accuracy: 0.9836\n",
            "Epoch 164/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 6.9942e-04 - accuracy: 0.9836 - val_loss: 0.0012 - val_accuracy: 0.9825\n",
            "Epoch 165/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.5282e-04 - accuracy: 0.9862 - val_loss: 0.0012 - val_accuracy: 0.9825\n",
            "Epoch 166/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 5.1491e-04 - accuracy: 0.9871 - val_loss: 0.0011 - val_accuracy: 0.9851\n",
            "Epoch 167/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.8930e-04 - accuracy: 0.9877 - val_loss: 0.0011 - val_accuracy: 0.9848\n",
            "Epoch 168/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.7006e-04 - accuracy: 0.9880 - val_loss: 0.0011 - val_accuracy: 0.9855\n",
            "Epoch 169/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.5373e-04 - accuracy: 0.9884 - val_loss: 0.0013 - val_accuracy: 0.9852\n",
            "Epoch 170/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.4532e-04 - accuracy: 0.9886 - val_loss: 0.0012 - val_accuracy: 0.9857\n",
            "Epoch 171/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.4174e-04 - accuracy: 0.9887 - val_loss: 0.0012 - val_accuracy: 0.9858\n",
            "Epoch 172/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.3774e-04 - accuracy: 0.9888 - val_loss: 0.0012 - val_accuracy: 0.9854\n",
            "Epoch 173/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 6.1594e-04 - accuracy: 0.9853 - val_loss: 0.0012 - val_accuracy: 0.9846\n",
            "Epoch 174/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.8740e-04 - accuracy: 0.9877 - val_loss: 0.0011 - val_accuracy: 0.9853\n",
            "Epoch 175/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.5599e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9855\n",
            "Epoch 176/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.5021e-04 - accuracy: 0.9885 - val_loss: 0.0012 - val_accuracy: 0.9855\n",
            "Epoch 177/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.4111e-04 - accuracy: 0.9887 - val_loss: 0.0012 - val_accuracy: 0.9857\n",
            "Epoch 178/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.3454e-04 - accuracy: 0.9889 - val_loss: 0.0012 - val_accuracy: 0.9851\n",
            "Epoch 179/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.3373e-04 - accuracy: 0.9889 - val_loss: 0.0012 - val_accuracy: 0.9853\n",
            "Epoch 180/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2889e-04 - accuracy: 0.9890 - val_loss: 0.0011 - val_accuracy: 0.9863\n",
            "Epoch 181/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2498e-04 - accuracy: 0.9891 - val_loss: 0.0012 - val_accuracy: 0.9861\n",
            "Epoch 182/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2816e-04 - accuracy: 0.9890 - val_loss: 0.0014 - val_accuracy: 0.9846\n",
            "Epoch 183/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2047e-04 - accuracy: 0.9892 - val_loss: 0.0011 - val_accuracy: 0.9862\n",
            "Epoch 184/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.1801e-04 - accuracy: 0.9893 - val_loss: 0.0013 - val_accuracy: 0.9854\n",
            "Epoch 185/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2187e-04 - accuracy: 0.9892 - val_loss: 0.0011 - val_accuracy: 0.9865\n",
            "Epoch 186/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2203e-04 - accuracy: 0.9892 - val_loss: 0.0012 - val_accuracy: 0.9862\n",
            "Epoch 187/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.2033e-04 - accuracy: 0.9892 - val_loss: 0.0012 - val_accuracy: 0.9862\n",
            "Epoch 188/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.2070e-04 - accuracy: 0.9892 - val_loss: 0.0012 - val_accuracy: 0.9858\n",
            "Epoch 189/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1865e-04 - accuracy: 0.9893 - val_loss: 0.0013 - val_accuracy: 0.9863\n",
            "Epoch 190/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2598e-04 - accuracy: 0.9891 - val_loss: 0.0013 - val_accuracy: 0.9852\n",
            "Epoch 191/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.4822e-04 - accuracy: 0.9886 - val_loss: 0.0012 - val_accuracy: 0.9862\n",
            "Epoch 192/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.1836e-04 - accuracy: 0.9893 - val_loss: 0.0012 - val_accuracy: 0.9862\n",
            "Epoch 193/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2904e-04 - accuracy: 0.9891 - val_loss: 0.0013 - val_accuracy: 0.9860\n",
            "Epoch 194/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.3062e-04 - accuracy: 0.9890 - val_loss: 0.0013 - val_accuracy: 0.9859\n",
            "Epoch 195/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2260e-04 - accuracy: 0.9892 - val_loss: 0.0012 - val_accuracy: 0.9856\n",
            "Epoch 196/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.1908e-04 - accuracy: 0.9893 - val_loss: 0.0012 - val_accuracy: 0.9864\n",
            "Epoch 197/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2513e-04 - accuracy: 0.9892 - val_loss: 0.0013 - val_accuracy: 0.9843\n",
            "Epoch 198/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2910e-04 - accuracy: 0.9891 - val_loss: 0.0013 - val_accuracy: 0.9853\n",
            "Epoch 199/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2400e-04 - accuracy: 0.9892 - val_loss: 0.0012 - val_accuracy: 0.9862\n",
            "Epoch 200/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.4598e-04 - accuracy: 0.9887 - val_loss: 0.0013 - val_accuracy: 0.9851\n",
            "Epoch 201/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.5816e-04 - accuracy: 0.9885 - val_loss: 0.0013 - val_accuracy: 0.9847\n",
            "Epoch 202/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.3785e-04 - accuracy: 0.9889 - val_loss: 0.0013 - val_accuracy: 0.9848\n",
            "Epoch 203/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.0025e-04 - accuracy: 0.9881 - val_loss: 0.0026 - val_accuracy: 0.9718\n",
            "Epoch 204/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.0745e-04 - accuracy: 0.9822 - val_loss: 0.0036 - val_accuracy: 0.9609\n",
            "Epoch 205/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.6679e-04 - accuracy: 0.9844 - val_loss: 0.0011 - val_accuracy: 0.9836\n",
            "Epoch 206/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.0305e-04 - accuracy: 0.9875 - val_loss: 0.0011 - val_accuracy: 0.9853\n",
            "Epoch 207/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.6138e-04 - accuracy: 0.9883 - val_loss: 0.0011 - val_accuracy: 0.9858\n",
            "Epoch 208/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.4667e-04 - accuracy: 0.9887 - val_loss: 0.0012 - val_accuracy: 0.9852\n",
            "Epoch 209/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.3540e-04 - accuracy: 0.9890 - val_loss: 0.0011 - val_accuracy: 0.9862\n",
            "Epoch 210/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.4204e-04 - accuracy: 0.9889 - val_loss: 0.0011 - val_accuracy: 0.9851\n",
            "Epoch 211/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.7556e-04 - accuracy: 0.9881 - val_loss: 0.0011 - val_accuracy: 0.9861\n",
            "Epoch 212/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.3157e-04 - accuracy: 0.9890 - val_loss: 0.0011 - val_accuracy: 0.9863\n",
            "Epoch 213/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.2245e-04 - accuracy: 0.9893 - val_loss: 0.0011 - val_accuracy: 0.9865\n",
            "Epoch 214/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1506e-04 - accuracy: 0.9894 - val_loss: 0.0012 - val_accuracy: 0.9860\n",
            "Epoch 215/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1026e-04 - accuracy: 0.9895 - val_loss: 0.0012 - val_accuracy: 0.9858\n",
            "Epoch 216/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.0543e-04 - accuracy: 0.9896 - val_loss: 0.0012 - val_accuracy: 0.9866\n",
            "Epoch 217/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0305e-04 - accuracy: 0.9897 - val_loss: 0.0012 - val_accuracy: 0.9867\n",
            "Epoch 218/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0200e-04 - accuracy: 0.9897 - val_loss: 0.0013 - val_accuracy: 0.9861\n",
            "Epoch 219/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0432e-04 - accuracy: 0.9897 - val_loss: 0.0012 - val_accuracy: 0.9867\n",
            "Epoch 220/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0082e-04 - accuracy: 0.9898 - val_loss: 0.0012 - val_accuracy: 0.9867\n",
            "Epoch 221/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9999e-04 - accuracy: 0.9898 - val_loss: 0.0013 - val_accuracy: 0.9863\n",
            "Epoch 222/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0261e-04 - accuracy: 0.9897 - val_loss: 0.0011 - val_accuracy: 0.9871\n",
            "Epoch 223/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9913e-04 - accuracy: 0.9898 - val_loss: 0.0012 - val_accuracy: 0.9866\n",
            "Epoch 224/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.2017e-04 - accuracy: 0.9894 - val_loss: 0.0012 - val_accuracy: 0.9860\n",
            "Epoch 225/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0866e-04 - accuracy: 0.9896 - val_loss: 0.0011 - val_accuracy: 0.9870\n",
            "Epoch 226/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0466e-04 - accuracy: 0.9897 - val_loss: 0.0011 - val_accuracy: 0.9866\n",
            "Epoch 227/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0418e-04 - accuracy: 0.9897 - val_loss: 0.0012 - val_accuracy: 0.9868\n",
            "Epoch 228/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9695e-04 - accuracy: 0.9899 - val_loss: 0.0012 - val_accuracy: 0.9868\n",
            "Epoch 229/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9791e-04 - accuracy: 0.9899 - val_loss: 0.0012 - val_accuracy: 0.9866\n",
            "Epoch 230/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0117e-04 - accuracy: 0.9898 - val_loss: 0.0012 - val_accuracy: 0.9869\n",
            "Epoch 231/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 0.0015 - accuracy: 0.9716 - val_loss: 0.0052 - val_accuracy: 0.9014\n",
            "Epoch 232/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0029 - accuracy: 0.9403 - val_loss: 0.0019 - val_accuracy: 0.9641\n",
            "Epoch 233/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0013 - accuracy: 0.9701 - val_loss: 0.0017 - val_accuracy: 0.9701\n",
            "Epoch 234/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 0.0010 - accuracy: 0.9756 - val_loss: 0.0016 - val_accuracy: 0.9737\n",
            "Epoch 235/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 8.7843e-04 - accuracy: 0.9784 - val_loss: 0.0018 - val_accuracy: 0.9736\n",
            "Epoch 236/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 7.9011e-04 - accuracy: 0.9802 - val_loss: 0.0016 - val_accuracy: 0.9762\n",
            "Epoch 237/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 7.3403e-04 - accuracy: 0.9815 - val_loss: 0.0017 - val_accuracy: 0.9763\n",
            "Epoch 238/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 6.8791e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9777\n",
            "Epoch 239/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 6.7396e-04 - accuracy: 0.9830 - val_loss: 0.0015 - val_accuracy: 0.9787\n",
            "Epoch 240/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 6.3117e-04 - accuracy: 0.9839 - val_loss: 0.0014 - val_accuracy: 0.9801\n",
            "Epoch 241/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 6.0422e-04 - accuracy: 0.9846 - val_loss: 0.0014 - val_accuracy: 0.9804\n",
            "Epoch 242/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 5.7919e-04 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 0.9799\n",
            "Epoch 243/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 5.5836e-04 - accuracy: 0.9857 - val_loss: 0.0014 - val_accuracy: 0.9817\n",
            "Epoch 244/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 5.4782e-04 - accuracy: 0.9861 - val_loss: 0.0012 - val_accuracy: 0.9826\n",
            "Epoch 245/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 5.3508e-04 - accuracy: 0.9863 - val_loss: 0.0013 - val_accuracy: 0.9825\n",
            "Epoch 246/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 5.1377e-04 - accuracy: 0.9869 - val_loss: 0.0014 - val_accuracy: 0.9823\n",
            "Epoch 247/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.9490e-04 - accuracy: 0.9873 - val_loss: 0.0013 - val_accuracy: 0.9833\n",
            "Epoch 248/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.9289e-04 - accuracy: 0.9874 - val_loss: 0.0012 - val_accuracy: 0.9839\n",
            "Epoch 249/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.7955e-04 - accuracy: 0.9878 - val_loss: 0.0014 - val_accuracy: 0.9831\n",
            "Epoch 250/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.6426e-04 - accuracy: 0.9881 - val_loss: 0.0011 - val_accuracy: 0.9851\n",
            "Epoch 251/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.5644e-04 - accuracy: 0.9883 - val_loss: 0.0012 - val_accuracy: 0.9849\n",
            "Epoch 252/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.5095e-04 - accuracy: 0.9885 - val_loss: 0.0012 - val_accuracy: 0.9852\n",
            "Epoch 253/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.4259e-04 - accuracy: 0.9887 - val_loss: 0.0011 - val_accuracy: 0.9858\n",
            "Epoch 254/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.4006e-04 - accuracy: 0.9888 - val_loss: 0.0012 - val_accuracy: 0.9849\n",
            "Epoch 255/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.3371e-04 - accuracy: 0.9889 - val_loss: 0.0012 - val_accuracy: 0.9858\n",
            "Epoch 256/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.2588e-04 - accuracy: 0.9891 - val_loss: 0.0012 - val_accuracy: 0.9858\n",
            "Epoch 257/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1904e-04 - accuracy: 0.9893 - val_loss: 0.0013 - val_accuracy: 0.9855\n",
            "Epoch 258/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1474e-04 - accuracy: 0.9894 - val_loss: 0.0012 - val_accuracy: 0.9860\n",
            "Epoch 259/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1206e-04 - accuracy: 0.9895 - val_loss: 0.0013 - val_accuracy: 0.9857\n",
            "Epoch 260/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.2214e-04 - accuracy: 0.9893 - val_loss: 0.0013 - val_accuracy: 0.9850\n",
            "Epoch 261/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1751e-04 - accuracy: 0.9894 - val_loss: 0.0012 - val_accuracy: 0.9856\n",
            "Epoch 262/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 6.7262e-04 - accuracy: 0.9852 - val_loss: 0.0016 - val_accuracy: 0.9726\n",
            "Epoch 263/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 6.7616e-04 - accuracy: 0.9840 - val_loss: 0.0011 - val_accuracy: 0.9838\n",
            "Epoch 264/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.9566e-04 - accuracy: 0.9876 - val_loss: 0.0012 - val_accuracy: 0.9841\n",
            "Epoch 265/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.5451e-04 - accuracy: 0.9885 - val_loss: 0.0012 - val_accuracy: 0.9854\n",
            "Epoch 266/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.4401e-04 - accuracy: 0.9888 - val_loss: 0.0011 - val_accuracy: 0.9862\n",
            "Epoch 267/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.2856e-04 - accuracy: 0.9891 - val_loss: 0.0013 - val_accuracy: 0.9853\n",
            "Epoch 268/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.2131e-04 - accuracy: 0.9893 - val_loss: 0.0013 - val_accuracy: 0.9855\n",
            "Epoch 269/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1879e-04 - accuracy: 0.9894 - val_loss: 0.0012 - val_accuracy: 0.9854\n",
            "Epoch 270/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1494e-04 - accuracy: 0.9894 - val_loss: 0.0013 - val_accuracy: 0.9858\n",
            "Epoch 271/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1280e-04 - accuracy: 0.9896 - val_loss: 0.0013 - val_accuracy: 0.9854\n",
            "Epoch 272/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.3777e-04 - accuracy: 0.9889 - val_loss: 0.0012 - val_accuracy: 0.9859\n",
            "Epoch 273/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1244e-04 - accuracy: 0.9895 - val_loss: 0.0013 - val_accuracy: 0.9854\n",
            "Epoch 274/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 4.1031e-04 - accuracy: 0.9896 - val_loss: 0.0013 - val_accuracy: 0.9860\n",
            "Epoch 275/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0509e-04 - accuracy: 0.9897 - val_loss: 0.0012 - val_accuracy: 0.9866\n",
            "Epoch 276/300\n",
            "168/168 [==============================] - 8s 45ms/step - loss: 3.9845e-04 - accuracy: 0.9898 - val_loss: 0.0012 - val_accuracy: 0.9863\n",
            "Epoch 277/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9685e-04 - accuracy: 0.9899 - val_loss: 0.0012 - val_accuracy: 0.9861\n",
            "Epoch 278/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9588e-04 - accuracy: 0.9899 - val_loss: 0.0013 - val_accuracy: 0.9863\n",
            "Epoch 279/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9595e-04 - accuracy: 0.9899 - val_loss: 0.0012 - val_accuracy: 0.9866\n",
            "Epoch 280/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9159e-04 - accuracy: 0.9900 - val_loss: 0.0013 - val_accuracy: 0.9865\n",
            "Epoch 281/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9398e-04 - accuracy: 0.9900 - val_loss: 0.0014 - val_accuracy: 0.9858\n",
            "Epoch 282/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9432e-04 - accuracy: 0.9900 - val_loss: 0.0012 - val_accuracy: 0.9863\n",
            "Epoch 283/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.8967e-04 - accuracy: 0.9901 - val_loss: 0.0013 - val_accuracy: 0.9862\n",
            "Epoch 284/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0343e-04 - accuracy: 0.9898 - val_loss: 0.0012 - val_accuracy: 0.9865\n",
            "Epoch 285/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9275e-04 - accuracy: 0.9900 - val_loss: 0.0012 - val_accuracy: 0.9867\n",
            "Epoch 286/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 8.1204e-04 - accuracy: 0.9823 - val_loss: 0.0011 - val_accuracy: 0.9828\n",
            "Epoch 287/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 5.2298e-04 - accuracy: 0.9872 - val_loss: 0.0011 - val_accuracy: 0.9854\n",
            "Epoch 288/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.6181e-04 - accuracy: 0.9885 - val_loss: 0.0012 - val_accuracy: 0.9857\n",
            "Epoch 289/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.2320e-04 - accuracy: 0.9893 - val_loss: 0.0012 - val_accuracy: 0.9862\n",
            "Epoch 290/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0841e-04 - accuracy: 0.9896 - val_loss: 0.0013 - val_accuracy: 0.9861\n",
            "Epoch 291/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9997e-04 - accuracy: 0.9898 - val_loss: 0.0013 - val_accuracy: 0.9863\n",
            "Epoch 292/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9712e-04 - accuracy: 0.9899 - val_loss: 0.0012 - val_accuracy: 0.9864\n",
            "Epoch 293/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.2573e-04 - accuracy: 0.9893 - val_loss: 0.0012 - val_accuracy: 0.9862\n",
            "Epoch 294/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9639e-04 - accuracy: 0.9900 - val_loss: 0.0012 - val_accuracy: 0.9866\n",
            "Epoch 295/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.8889e-04 - accuracy: 0.9901 - val_loss: 0.0012 - val_accuracy: 0.9868\n",
            "Epoch 296/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.5021e-04 - accuracy: 0.9888 - val_loss: 0.0012 - val_accuracy: 0.9857\n",
            "Epoch 297/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.1799e-04 - accuracy: 0.9895 - val_loss: 0.0012 - val_accuracy: 0.9867\n",
            "Epoch 298/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 4.0028e-04 - accuracy: 0.9898 - val_loss: 0.0012 - val_accuracy: 0.9870\n",
            "Epoch 299/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9119e-04 - accuracy: 0.9900 - val_loss: 0.0013 - val_accuracy: 0.9863\n",
            "Epoch 300/300\n",
            "168/168 [==============================] - 8s 46ms/step - loss: 3.9012e-04 - accuracy: 0.9901 - val_loss: 0.0012 - val_accuracy: 0.9866\n",
            "Total model fit time:  2301.564504146576 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/datamining/prisma/Sardinia/deepUNet_300Ep4ClassesNoNoise')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwVfED5jKLuF",
        "outputId": "cef0b7bd-42bd-4c02-c795-4b30ddb6ffff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/datamining/prisma/Sardinia/deepUNet_300Ep4ClassesNoNoise/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minutes_fit_time =(2301.564504146576)/60\n",
        "print(minutes_fit_time, \"minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4fSJLWThiIq",
        "outputId": "2f74729a-2329-49c0-bf8e-70cab21c7544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38.35940840244293 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'g', label='Validation Accuracy')\n",
        "plt.title('Training and validation Accuracy balanced model')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Hok3pMAuKLw7",
        "outputId": "dbb62700-b16c-497e-df41-f16dcbcf9bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#label_masks={0 : \"background\",1 : 'sea', 2 : \"vegetation\", 3 : \"miner\"} "
      ],
      "metadata": {
        "id": "Hr2Rr7EhQ8ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(X_test)"
      ],
      "metadata": {
        "id": "l5XlCo8bKLza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbUcZkO-S1Ir",
        "outputId": "0527dd7b-e30b-4629-ee38-6c05f2264588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(292, 128, 128, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_img=np.argmax(prediction, axis=3)[45,:,:]"
      ],
      "metadata": {
        "id": "K2pWEamqTxG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x39VGGTdUJLf",
        "outputId": "2aea9bcc-2b42-4901-8d57-be4355ebd437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PREDICTION\")\n",
        "plt.imshow(predicted_img)\n",
        "plt.show()\n",
        "print(np.unique(predicted_img))\n",
        "print(\"GROUND TRUTH\")\n",
        "plt.imshow(y_test[45,:,:,0])\n",
        "plt.show()\n",
        "print(np.unique(y_test[45,:,:,0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "myLNC3dTS8jT",
        "outputId": "a09820f6-1549-478e-981c-ee7d14d8bc3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREDICTION\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4 5]\n",
            "GROUND TRUTH\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HAnWL8RQUV4N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}